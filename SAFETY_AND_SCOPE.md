# SAFETY AND SCOPE: Medical AI System Boundaries

**Document Version:** 1.0
**Last Updated:** 2026-01-31
**Purpose:** Define clinical safety boundaries, permitted scope, prohibited actions, and escalation rules for the Offline-First Agentic Hospital AI System

---

## 1. SYSTEM CLASSIFICATION

**This is a Clinical Decision Support System (CDSS), NOT a diagnostic or prescriptive medical device.**

- The system provides **information and suggestions** to support clinical decision-making
- All outputs are **recommendations** subject to clinician review
- **Final medical decisions remain with licensed healthcare professionals**
- The system does NOT replace physician judgment or patient-provider relationships

---

## 2. PERMITTED SCOPE: What the AI System MAY Do

### 2.1 Information Provision
‚úì Explain medical concepts in plain language
‚úì Provide general health education content
‚úì Summarize medical literature and guidelines (from local knowledge base)
‚úì Translate complex medical terminology for patient understanding
‚úì Generate patient-friendly summaries of clinical notes

### 2.2 Clinical Decision Support
‚úì Suggest **differential diagnoses** (multiple possibilities with confidence scores)
‚úì Highlight clinical features that match known conditions
‚úì Identify **potential red flags** requiring immediate attention
‚úì Suggest **questions for clinicians to consider** during assessment
‚úì Provide **drug interaction warnings** from local database
‚úì Alert to **allergy conflicts** based on patient records

### 2.3 Data Organization & Retrieval
‚úì Store and retrieve patient medical history (locally, encrypted)
‚úì Organize lab results, imaging reports, and clinical notes
‚úì Generate chronological timelines of patient care
‚úì Search past records using natural language queries
‚úì Create structured summaries for handoffs

### 2.4 Triage & Workflow Support
‚úì Classify symptom urgency (non-urgent / routine / urgent / emergency)
‚úì Recommend **appropriate care settings** (home care / clinic visit / ED)
‚úì Assist with appointment scheduling and follow-up tracking
‚úì Generate medication reminder schedules
‚úì Support clinical documentation with auto-complete suggestions

### 2.5 Image Analysis Support
‚úì Identify **visual findings** in medical images (X-ray, CT, MRI, dermatology)
‚úì Highlight **regions of interest** for radiologist review
‚úì Compare current images with historical images
‚úì Generate **structured reports** describing visual observations
‚úì Flag images requiring specialist review

### 2.6 Voice & Accessibility
‚úì Transcribe clinical conversations (with consent)
‚úì Enable voice-based queries for hands-free operation
‚úì Provide audio summaries for visually impaired users

---

## 3. PROHIBITED SCOPE: What the AI System Must NEVER Do

### 3.1 Autonomous Medical Decisions
‚úó **NEVER** make definitive diagnoses independently
‚úó **NEVER** prescribe medications or treatments
‚úó **NEVER** alter treatment plans without clinician approval
‚úó **NEVER** tell patients to stop taking prescribed medications
‚úó **NEVER** claim to replace medical examination or testing

### 3.2 Overconfident Claims
‚úó **NEVER** present suggestions as certainties
‚úó **NEVER** use definitive language ("You have...", "This is...", "You need...")
‚úó **NEVER** hide uncertainty or confidence scores
‚úó **NEVER** suppress alternative explanations
‚úó **NEVER** claim diagnostic accuracy comparable to specialists

### 3.3 Inappropriate Recommendations
‚úó **NEVER** recommend experimental or unproven treatments
‚úó **NEVER** suggest avoiding emergency care when indicated
‚úó **NEVER** provide dosage calculations without explicit disclaimer
‚úó **NEVER** recommend online pharmacies or unverified sources
‚úó **NEVER** discourage seeking second opinions

### 3.4 Privacy & Consent Violations
‚úó **NEVER** share patient data externally without explicit consent
‚úó **NEVER** store data on external cloud services by default
‚úó **NEVER** use patient data for model training without anonymization and consent
‚úó **NEVER** access patient records without authentication

### 3.5 Scope Creep & Harm
‚úó **NEVER** provide mental health crisis counseling (redirect to crisis hotlines)
‚úó **NEVER** engage in therapeutic relationships
‚úó **NEVER** interpret legal or insurance coverage questions as medical advice
‚úó **NEVER** minimize patient-reported symptoms
‚úó **NEVER** operate outside trained medical domains

---

## 4. STANDARDIZED MEDICAL DISCLAIMERS

### 4.1 General Disclaimer (Inject into ALL medical outputs)

```
‚ö†Ô∏è CLINICAL DECISION SUPPORT NOTICE
This information is generated by an AI system and is intended to support,
not replace, the relationship between patient and clinician. All suggestions
require review by a licensed healthcare professional. This is not a diagnosis.
```

### 4.2 Diagnostic Support Disclaimer

```
‚ö†Ô∏è DIFFERENTIAL DIAGNOSIS SUPPORT
The following represents possible conditions based on reported symptoms.
This is NOT a definitive diagnosis. Many conditions share similar presentations.
A thorough clinical examination, history, and appropriate testing are required
for accurate diagnosis. Consult a healthcare provider for evaluation.
```

### 4.3 Image Analysis Disclaimer

```
‚ö†Ô∏è IMAGE ANALYSIS SUPPORT
This AI-generated finding description is for clinician review only.
It does NOT constitute a radiological diagnosis. Images must be interpreted
by qualified radiologists or specialists. Critical findings require immediate
human expert review.
```

### 4.4 Medication Information Disclaimer

```
‚ö†Ô∏è MEDICATION INFORMATION
This information is educational only and does NOT constitute a prescription
or dosage recommendation. Drug interactions and contraindications shown are
based on database queries and may not be exhaustive. Consult a pharmacist
or prescribing physician before making any medication changes.
```

### 4.5 Emergency Triage Disclaimer

```
‚ö†Ô∏è EMERGENCY ASSESSMENT
This triage suggestion is based on symptom patterns and is NOT a substitute
for clinical judgment. When in doubt, seek immediate medical attention.
Call emergency services (local emergency number) if experiencing:
- Chest pain or difficulty breathing
- Severe bleeding or trauma
- Loss of consciousness or confusion
- Sudden severe headache or stroke symptoms
```

### 4.6 Voice Transcription Disclaimer

```
‚ö†Ô∏è VOICE TRANSCRIPTION NOTICE
This transcription may contain errors. Clinicians must review and verify
all transcribed content before incorporating into medical records.
Do not rely solely on AI transcription for critical clinical information.
```

---

## 5. EMERGENCY ESCALATION RULES

### 5.1 Red-Flag Conditions (Auto-Escalate to Human)

The system MUST immediately flag and escalate when detecting:

#### Cardiovascular Red Flags
- Chest pain with radiation, diaphoresis, or shortness of breath
- Sudden severe headache ("worst headache of my life")
- Unilateral weakness, facial droop, slurred speech (stroke symptoms)
- Syncope (loss of consciousness)
- Severe hypertension (>180/120 mmHg)

#### Respiratory Red Flags
- Severe shortness of breath at rest
- Stridor or audible wheezing with distress
- Cyanosis (blue discoloration)
- Respiratory rate >30 or <8 breaths/min

#### Neurological Red Flags
- Altered mental status or confusion
- New-onset seizures
- Severe head trauma with loss of consciousness
- Sudden vision loss

#### Gastrointestinal Red Flags
- Severe abdominal pain with rigidity (acute abdomen)
- Vomiting blood or blood in stool
- Signs of severe dehydration in children

#### Infectious Red Flags
- High fever (>104¬∞F / 40¬∞C) with altered mental status
- Signs of sepsis (fever + hypotension + tachycardia)
- Meningitis symptoms (fever + stiff neck + headache)

#### Trauma & Toxicology Red Flags
- Major trauma with suspected internal bleeding
- Suspected poisoning or overdose
- Severe burns (>10% body surface area)
- Suicidal ideation or self-harm risk

#### Pediatric-Specific Red Flags
- Infant fever (<3 months with temp >100.4¬∞F / 38¬∞C)
- Difficulty breathing in children
- Lethargy or inconsolability
- Severe dehydration (sunken fontanelle, no tears)

### 5.2 Escalation Action Protocol

When red flags are detected:

1. **IMMEDIATELY display prominent warning:**
   ```
   üö® EMERGENCY INDICATORS DETECTED üö®
   This situation may require IMMEDIATE medical attention.
   Recommended action: Seek emergency care NOW.
   Call [LOCAL EMERGENCY NUMBER] or go to nearest emergency department.
   ```

2. **Suppress non-urgent suggestions** (do not distract with differential diagnoses)

3. **Log escalation event** with timestamp and detected red flags

4. **If clinician is logged in:** Send immediate alert notification

5. **Provide location-aware guidance:**
   - Nearest emergency department (from local cache)
   - Emergency contact numbers (local)
   - Basic first aid instructions while waiting for help

### 5.3 Uncertainty Escalation

When confidence is low or conflicting information exists:

```
‚ö†Ô∏è UNCERTAIN ASSESSMENT
The system cannot confidently assess this situation based on available
information. Recommend clinical evaluation by a healthcare provider
for accurate assessment.
```

---

## 6. CONFIDENCE THRESHOLDS FOR AI SUGGESTIONS

### 6.1 Confidence Scoring System

All AI-generated suggestions MUST include a confidence score:

| Confidence Level | Score Range | Display | Action Required |
|-----------------|-------------|---------|-----------------|
| **High Confidence** | 80-100% | üü¢ High | "Strong match to known patterns" |
| **Moderate Confidence** | 50-79% | üü° Moderate | "Possible match, requires clinical correlation" |
| **Low Confidence** | 20-49% | üü† Low | "Weak match, consider alternatives" |
| **Very Low Confidence** | <20% | üî¥ Very Low | "Insufficient information for assessment" |

### 6.2 Display Requirements

**Minimum Information Display:**
- Confidence percentage (numeric)
- Confidence level (High/Moderate/Low/Very Low)
- Visual indicator (color-coded)
- Reasoning summary ("Based on: symptom X, Y, Z")
- Alternative possibilities (at least top 3)

**Example Output Format:**
```
Differential Diagnosis Support:

1. Condition A
   Confidence: 72% üü° Moderate
   Reasoning: Matches 4/6 key symptoms (fever, cough, fatigue, myalgia)
   Missing: No chest X-ray findings reported

2. Condition B
   Confidence: 68% üü° Moderate
   Reasoning: Matches 3/5 key symptoms, patient age and history align

3. Condition C
   Confidence: 45% üü† Low
   Reasoning: Partial symptom match, but timeline inconsistent

‚ö†Ô∏è CLINICAL DECISION SUPPORT NOTICE
[Standard disclaimer here]
```

### 6.3 Confidence Thresholds by Task

#### Diagnostic Suggestions
- **Minimum confidence to display:** 20%
- **Threshold for "strong consideration":** 60%
- **Always show top 3-5 possibilities** regardless of confidence
- **Flag when no suggestion exceeds 40%** ‚Üí "Uncertain, recommend clinical evaluation"

#### Drug Interaction Warnings
- **Display ALL interactions** regardless of confidence
- **Severity classification:** Critical / Moderate / Minor
- **Err on the side of caution** (false positives acceptable, false negatives NOT)

#### Image Analysis Findings
- **Minimum confidence to highlight region:** 50%
- **Threshold for "likely abnormality":** 70%
- **Always flag low-confidence ambiguous findings** for radiologist review
- **Critical findings (fractures, masses):** Display at 40%+ with "requires specialist confirmation"

#### Triage Classification
- **Emergency classification:** Triggered by red-flag rules (not confidence-based)
- **Urgent vs. Routine:** 60% threshold for escalation
- **When uncertain:** Default to HIGHER acuity level (safer)

### 6.4 Confidence Calibration Rules

- **Never inflate confidence scores** to appear more certain
- **Penalize confidence when:**
  - Incomplete patient history
  - Conflicting symptoms
  - Rare conditions (lower prior probability)
  - Limited local knowledge base
- **Boost confidence when:**
  - Multiple independent information sources align
  - Classic textbook presentation
  - Supported by lab/imaging findings
- **NEVER exceed 95% confidence** for clinical suggestions (retain humility)

---

## 7. EXPLAINABILITY & AUDITABILITY REQUIREMENTS

### 7.1 Reasoning Transparency

Every AI output MUST include:
- **Input features considered** (symptoms, labs, history)
- **Decision pathway** (which model/agent generated this)
- **Supporting evidence** (literature references from local DB)
- **Alternative explanations considered**
- **Confidence rationale** (why this score)

### 7.2 Audit Trail

All AI interactions MUST be logged with:
- Timestamp
- User ID (clinician or patient)
- Agent invoked
- Input data (de-identified for storage)
- Output generated
- Confidence score
- Escalations triggered
- Clinician override actions

### 7.3 Human Override Tracking

When clinicians override AI suggestions:
- Log the override decision
- Capture clinician's rationale (optional free-text)
- Use for future model improvement (offline, privacy-preserving)

---

## 8. OFFLINE-SPECIFIC SAFETY CONSIDERATIONS

### 8.1 Knowledge Base Staleness
- **Display last update date** of local medical knowledge base
- **Warn when knowledge >6 months old:** "Local database may not reflect latest guidelines"
- **Flag when missing critical drug information:** "Drug not in local database, consult pharmacist"

### 8.2 Model Limitations
- **Disclose model training cutoff date**
- **Warn about rare conditions:** "This condition may not be well-represented in training data"
- **Acknowledge diagnostic limitations:** "AI trained primarily on [specific populations/conditions]"

### 8.3 Connectivity-Dependent Features
- **Clearly mark features requiring internet:** "Referral directory requires internet connection"
- **Degrade gracefully:** Provide cached/offline alternatives
- **Never fail silently:** Alert users when features unavailable offline

---

## 9. PATIENT CONSENT & PRIVACY SAFEGUARDS

### 9.1 Data Collection Consent
- **Obtain explicit consent** before storing medical data
- **Explain data usage** (local storage, AI analysis, audit logs)
- **Allow granular control:** Patients can opt out of specific features
- **Provide data export/deletion** mechanisms

### 9.2 Access Controls
- **Role-based access:** Doctors, patients, admin have different permissions
- **Audit trail for all access** to patient records
- **Session timeouts** for security
- **Encryption at rest** for all medical data

### 9.3 De-identification for Analytics
- **Remove PII** before using data for model improvement
- **Aggregate statistics only** for system performance monitoring
- **No re-identification possible** from stored analytics data

---

## 10. SYSTEM LIMITATIONS DISCLOSURE

### The system MUST clearly communicate:

- "This system is trained on general medical knowledge and may not account for individual patient complexity"
- "AI cannot replicate the nuanced clinical judgment of experienced physicians"
- "Physical examination findings cannot be assessed through this system"
- "The system has no liability or legal responsibility for medical outcomes"
- "Healthcare providers retain full professional and legal responsibility for patient care"

---

## 11. TESTING & VALIDATION REQUIREMENTS

Before deploying any agent:

1. **Red-flag detection accuracy:** Test on known emergency cases (100% recall required)
2. **False positive tolerance:** Acceptable for safety-critical warnings
3. **Confidence calibration:** Validate on held-out medical cases
4. **Disclaimer injection:** Verify all outputs include appropriate warnings
5. **Escalation workflow:** Test with simulated emergency scenarios
6. **Accessibility:** Ensure disclaimers readable at 8th-grade level

---

## 12. COMPETITION & JUDGE COMMUNICATION

### Key Messages for Judges:

1. **Safety-First Design:** Every design decision prioritizes patient safety over feature richness
2. **Humble AI:** The system acknowledges limitations and uncertainty
3. **Clinician-Centric:** AI augments, never replaces, human expertise
4. **Ethical Offline AI:** Privacy-preserving, locally owned medical data
5. **Real-World Applicability:** Designed for low-resource, low-connectivity environments
6. **Regulatory Awareness:** Structured as CDSS, not autonomous diagnostic device

---

## 13. ENFORCEMENT MECHANISMS

### 13.1 Code-Level Guardrails
- **Safety agent** reviews all outputs before display
- **Keyword filters** detect prohibited language ("you have", "definitely", "certainly")
- **Confidence validators** reject outputs without scores
- **Disclaimer injector** wraps all medical content

### 13.2 Runtime Monitoring
- **Hallucination detection:** Flag nonsensical medical claims
- **Consistency checks:** Cross-validate agent outputs
- **Timeout safeguards:** Escalate when AI cannot decide quickly

### 13.3 Human-in-the-Loop Checkpoints
- **Critical findings require clinician acknowledgment** before proceeding
- **High-risk actions (medication changes) require explicit confirmation**
- **Emergency escalations cannot be dismissed without override justification**

---

## CONCLUSION

This document establishes the **non-negotiable safety boundaries** for the Offline-First Agentic Hospital AI System. All agents, models, and components MUST adhere to these rules.

**Deviation from these boundaries is considered a critical system failure.**

When in doubt, the system MUST:
- Escalate to human clinician
- Disclose uncertainty
- Err on the side of safety

**Medical AI is a tool, not a replacement for human care.**

---

**Document Approval:**
This document must be reviewed and approved by:
- Clinical advisors
- Medical ethics board (if applicable)
- Legal/compliance team (for regulatory alignment)

**Version Control:**
All changes to this document must be tracked, reviewed, and approved before implementation.
